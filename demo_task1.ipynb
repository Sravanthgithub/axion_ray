{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "def handle_privacy_notice(driver, max_wait=10):\n",
    "    \"\"\"\n",
    "    Handle the privacy notice popup by finding and clicking the close button\n",
    "    Returns True if successfully closed, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wait for privacy notice to appear and become clickable\n",
    "        wait = WebDriverWait(driver, max_wait)\n",
    "        close_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.ID, \"onetrust-close-btn-container\"))\n",
    "        )\n",
    "        \n",
    "        # Trying different click methods\n",
    "        try:\n",
    "            close_button.click()\n",
    "        except:\n",
    "            try:\n",
    "                ActionChains(driver).move_to_element(close_button).click().perform()\n",
    "            except:\n",
    "                driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "        \n",
    "        # Wait for popup to disappear\n",
    "        time.sleep(1)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error handling privacy notice: {e}\")\n",
    "        return False\n",
    "\n",
    "def fetch_and_save_html(url, output_file=\"bestbuy_reviews.html\", max_attempts=20):\n",
    "    \"\"\"\n",
    "    Use Selenium to load the page, handle privacy notice, click 'Show More', and save the final HTML\n",
    "    \"\"\"\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    action = ActionChains(driver)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Opening URL: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Initial load wait\n",
    "        \n",
    "        # Handle privacy notice\n",
    "        if not handle_privacy_notice(driver):\n",
    "            print(\"Warning: Could not handle privacy notice\")\n",
    "        \n",
    "        attempts = 0\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                # Wait for Show More button to be present and visible\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                show_more = wait.until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (By.CSS_SELECTOR, \"div[data-automation='load-more-button'] a.loadMoreLink_2cY6X\")\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Scroll into view\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", show_more)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Click using different methods until one works\n",
    "                try:\n",
    "                    show_more.click()\n",
    "                except:\n",
    "                    try:\n",
    "                        action.move_to_element(show_more).click().perform()\n",
    "                    except:\n",
    "                        driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "                \n",
    "                print(f\"Clicked Show More button (attempt {attempts + 1})\")\n",
    "                time.sleep(2)  # Wait for new content to load\n",
    "                attempts += 1\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print(\"No more Show More button found\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error clicking button: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Wait longer before saving HTML to ensure all content is loaded\n",
    "        print(\"Waiting for final content to load completely...\")\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # Save the final HTML\n",
    "        print(\"Saving final HTML...\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(driver.page_source)\n",
    "        \n",
    "        print(f\"HTML saved to {output_file}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening URL: https://www.bestbuy.ca/en-ca/product/google-pixel-9-pro-256gb-hazel-unlocked/18165489/review\n",
      "Clicked Show More button (attempt 1)\n",
      "Clicked Show More button (attempt 2)\n",
      "Clicked Show More button (attempt 3)\n",
      "Clicked Show More button (attempt 4)\n",
      "Clicked Show More button (attempt 5)\n",
      "Error clicking button: Message: \n",
      "Stacktrace:\n",
      "#0 0x5752cf3dcc5a <unknown>\n",
      "#1 0x5752cf0bfe2c <unknown>\n",
      "#2 0x5752cf10c661 <unknown>\n",
      "#3 0x5752cf10c751 <unknown>\n",
      "#4 0x5752cf150f64 <unknown>\n",
      "#5 0x5752cf12f5ed <unknown>\n",
      "#6 0x5752cf14e303 <unknown>\n",
      "#7 0x5752cf12f363 <unknown>\n",
      "#8 0x5752cf0ff247 <unknown>\n",
      "#9 0x5752cf0ffb9e <unknown>\n",
      "#10 0x5752cf3a322b <unknown>\n",
      "#11 0x5752cf3a72d1 <unknown>\n",
      "#12 0x5752cf38eade <unknown>\n",
      "#13 0x5752cf3a7e32 <unknown>\n",
      "#14 0x5752cf37377f <unknown>\n",
      "#15 0x5752cf3cc618 <unknown>\n",
      "#16 0x5752cf3cc7f0 <unknown>\n",
      "#17 0x5752cf3dbd8c <unknown>\n",
      "#18 0x75bfc2894ac3 <unknown>\n",
      "\n",
      "Waiting for final content to load completely...\n",
      "Saving final HTML...\n",
      "HTML saved to bestbuy_reviews.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://www.bestbuy.ca/en-ca/product/google-pixel-9-pro-256gb-hazel-unlocked/18165489/review\"\n",
    "\n",
    "try:\n",
    "    fetch_and_save_html(url)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def find_element_by_partial_class(container, element_type, partial_class):\n",
    "    \"\"\"\n",
    "    Helper function to find elements with class names starting with the given prefix\n",
    "    \"\"\"\n",
    "    elements = container.find_all(element_type, class_=lambda x: x and x.startswith(partial_class))\n",
    "    return elements[0] if elements else None\n",
    "\n",
    "def parse_reviews_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    reviews_data = []\n",
    "    \n",
    "    # Find all review containers - looking for classes starting with 'reviewContent'\n",
    "    reviews = soup.find_all(lambda tag: tag.get('class') and \n",
    "                          any(cls.startswith('reviewContent') for cls in tag.get('class')))\n",
    "    \n",
    "    for review in reviews:\n",
    "        # Get the parent container that holds all review information\n",
    "        review_container = review.parent\n",
    "        \n",
    "        # Extract review title - finding class starting with 'reviewTitle'\n",
    "        title = find_element_by_partial_class(review_container, 'div', 'reviewTitle')\n",
    "        title_text = title.get_text(strip=True) if title else ''\n",
    "        \n",
    "        # Extract reviewer info - finding class starting with 'reviewerInfo'\n",
    "        reviewer_info = find_element_by_partial_class(review_container, 'div', 'reviewerInfo')\n",
    "        if reviewer_info:\n",
    "            # Find author - class starting with 'author'\n",
    "            author = find_element_by_partial_class(reviewer_info, 'span', 'author')\n",
    "            author_name = author.find_all('span')[-1].get_text(strip=True) if author else ''\n",
    "            \n",
    "            # Find date - class starting with 'locationAndTime'\n",
    "            date_span = find_element_by_partial_class(reviewer_info, 'span', 'locationAndTime')\n",
    "            date_str = date_span.get('data-date') if date_span else ''\n",
    "            formatted_date = datetime.fromisoformat(date_str).strftime('%Y-%m-%d') if date_str else ''\n",
    "        else:\n",
    "            author_name = ''\n",
    "            formatted_date = ''\n",
    "        \n",
    "        # Extract review content\n",
    "        review_text = review.get_text(strip=True)\n",
    "        \n",
    "        # Extract syndication source - class starting with 'syndicationSource'\n",
    "        syndication = find_element_by_partial_class(review_container, 'p', 'syndicationSource')\n",
    "        source = syndication.get_text(strip=True) if syndication else ''\n",
    "        \n",
    "        # Check if it's a promotional review\n",
    "        is_promotional = '[This review was collected as part of a promotion.]' in review_text\n",
    "        clean_review = review_text.replace('[This review was collected as part of a promotion.]', '').strip()\n",
    "        \n",
    "        reviews_data.append({\n",
    "            'title': title_text,\n",
    "            'author': author_name,\n",
    "            'date': formatted_date,\n",
    "            'review_text': clean_review,\n",
    "            'is_promotional': is_promotional,\n",
    "            'source': source\n",
    "        })\n",
    "    \n",
    "    return reviews_data\n",
    "\n",
    "def save_to_csv(reviews_data, output_file='reviews.csv'):\n",
    "    if not reviews_data:\n",
    "        print(\"No reviews found!\")\n",
    "        return\n",
    "        \n",
    "    fieldnames = ['title', 'author', 'date', 'review_text', 'is_promotional', 'source']\n",
    "    \n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(reviews_data)\n",
    "        print(f\"Successfully saved {len(reviews_data)} reviews to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 reviews\n",
      "Successfully saved 58 reviews to reviews.csv\n"
     ]
    }
   ],
   "source": [
    "html_file = \"/home/sravanth/Documents/axion_ray/bestbuy_reviews.html\"\n",
    "with open(html_file, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "reviews_data = parse_reviews_html(html_content)\n",
    "print(f\"Found {len(reviews_data)} reviews\")\n",
    "save_to_csv(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/sravanth/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/sravanth/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sravanth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sravanth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def analyze_reviews(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initialize the NLTK sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Function to get sentiment scores\n",
    "    def get_sentiment(text):\n",
    "        return sia.polarity_scores(text)\n",
    "    \n",
    "    # Calculate sentiment scores for each review\n",
    "    sentiments = df['review_text'].apply(get_sentiment)\n",
    "    \n",
    "    # Extract sentiment scores into separate columns\n",
    "    df['compound'] = sentiments.apply(lambda x: x['compound'])\n",
    "    df['positive'] = sentiments.apply(lambda x: x['pos'])\n",
    "    df['negative'] = sentiments.apply(lambda x: x['neg'])\n",
    "    df['neutral'] = sentiments.apply(lambda x: x['neu'])\n",
    "    \n",
    "    # Classify overall sentiment\n",
    "    df['sentiment'] = df['compound'].apply(lambda x: 'Positive' if x > 0.05 \n",
    "                                         else ('Negative' if x < -0.05 else 'Neutral'))\n",
    "    \n",
    "    # Get most common words (excluding stopwords)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    all_words = ' '.join(df['review_text']).lower()\n",
    "    word_tokens = word_tokenize(all_words)\n",
    "    filtered_words = [word for word in word_tokens \n",
    "                     if word.isalnum() and word not in stop_words]\n",
    "    word_freq = Counter(filtered_words).most_common(10)\n",
    "    \n",
    "    # Calculate average sentiment scores\n",
    "    avg_scores = {\n",
    "        'Average Compound Score': df['compound'].mean(),\n",
    "        'Average Positive Score': df['positive'].mean(),\n",
    "        'Average Negative Score': df['negative'].mean(),\n",
    "        'Average Neutral Score': df['neutral'].mean()\n",
    "    }\n",
    "    \n",
    "    # Calculate sentiment distribution\n",
    "    sentiment_dist = df['sentiment'].value_counts()\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary = {\n",
    "        'Total Reviews': len(df),\n",
    "        'Average Sentiment Score': df['compound'].mean(),\n",
    "        'Positive Reviews': sentiment_dist.get('Positive', 0),\n",
    "        'Neutral Reviews': sentiment_dist.get('Neutral', 0),\n",
    "        'Negative Reviews': sentiment_dist.get('Negative', 0),\n",
    "        'Most Common Words': dict(word_freq),\n",
    "        'Average Scores': avg_scores\n",
    "    }\n",
    "    \n",
    "    return df, summary\n",
    "\n",
    "def plot_sentiment_distribution(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=df, x='compound', bins=20)\n",
    "    plt.title('Distribution of Sentiment Scores')\n",
    "    plt.xlabel('Compound Sentiment Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('sentiment_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_sentiment_categories(df):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df['sentiment'].value_counts().plot(kind='bar')\n",
    "    plt.title('Distribution of Sentiment Categories')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('sentiment_categories.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentiment Analysis Summary ===\n",
      "Total Reviews Analyzed: 58\n",
      "Average Sentiment Score: 0.929\n",
      "\n",
      "Sentiment Distribution:\n",
      "Positive Reviews: 58\n",
      "Neutral Reviews: 0\n",
      "Negative Reviews: 0\n",
      "\n",
      "Average Scores:\n",
      "Average Compound Score: 0.929\n",
      "Average Positive Score: 0.276\n",
      "Average Negative Score: 0.019\n",
      "Average Neutral Score: 0.704\n",
      "\n",
      "Top 10 Most Common Words:\n",
      "phone: 121\n",
      "pixel: 73\n",
      "camera: 58\n",
      "pro: 55\n",
      "google: 50\n",
      "9: 48\n",
      "battery: 44\n",
      "great: 37\n",
      "features: 35\n",
      "life: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Analyze reviews\n",
    "df, summary = analyze_reviews('/home/sravanth/Documents/axion_ray/reviews.csv')\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n=== Sentiment Analysis Summary ===\")\n",
    "print(f\"Total Reviews Analyzed: {summary['Total Reviews']}\")\n",
    "print(f\"Average Sentiment Score: {summary['Average Sentiment Score']:.3f}\")\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(f\"Positive Reviews: {summary['Positive Reviews']}\")\n",
    "print(f\"Neutral Reviews: {summary['Neutral Reviews']}\")\n",
    "print(f\"Negative Reviews: {summary['Negative Reviews']}\")\n",
    "\n",
    "print(\"\\nAverage Scores:\")\n",
    "for metric, score in summary['Average Scores'].items():\n",
    "    print(f\"{metric}: {score:.3f}\")\n",
    "\n",
    "print(\"\\nTop 10 Most Common Words:\")\n",
    "for word, count in summary['Most Common Words'].items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Generate plots\n",
    "plot_sentiment_distribution(df)\n",
    "plot_sentiment_categories(df)\n",
    "\n",
    "# Export detailed results to CSV\n",
    "df[['review_text', 'compound', 'positive', 'negative', 'neutral', 'sentiment']].to_csv(\n",
    "    'sentiment_analysis_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axion_ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
